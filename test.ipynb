{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xXkrH43GV-sW",
    "outputId": "37a9f19a-251d-40f5-dc9b-54779caf48e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EEAzrolWXQNc",
    "outputId": "fe1ef283-9b5b-404d-a777-0dbe6eb634f9"
   },
   "outputs": [],
   "source": [
    "!pip install traker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ONmWcrKn6A0y",
    "outputId": "e2c49982-d960-40e8-ab4a-f21eacc9b4c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch import nn as nn\n",
    "from torchvision.datasets import Food101, ImageFolder\n",
    "from trak import TRAKer\n",
    "from trak import modelout_functions\n",
    "from collections.abc import Iterable\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ue3_pIWcV1gm",
    "outputId": "33407e57-d744-4b67-dc3a-5320f920ca6d"
   },
   "outputs": [],
   "source": [
    "processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-18\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"microsoft/resnet-18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vYAkNawuV1gn"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = transforms.functional.pil_to_tensor(image)\n",
    "    processed_image = processor.preprocess(image)[\"pixel_values\"][0]\n",
    "    return torch.from_numpy(processed_image)\n",
    "\n",
    "train_dataset = Food101(\"data/food-101\", split=\"train\", transform=preprocess_image, download=False)\n",
    "test_dataset = Food101(\"data/food-101\", split=\"test\", transform=preprocess_image, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pc9PIg03V1go",
    "outputId": "eb67774c-28bb-4f6f-ff04-56b3ca9c71b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 3, 224, 224]), torch.Size([64]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "for X, y in train_dl:\n",
    "    break\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Coq666k5V1gp",
    "outputId": "bcabbae2-1697-457d-ee4c-6e0762eaa46b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetForImageClassification(\n",
       "  (resnet): ResNetModel(\n",
       "    (embedder): ResNetEmbeddings(\n",
       "      (embedder): ResNetConvLayer(\n",
       "        (convolution): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (encoder): ResNetEncoder(\n",
       "      (stages): ModuleList(\n",
       "        (0): ResNetStage(\n",
       "          (layers): Sequential(\n",
       "            (0): ResNetBasicLayer(\n",
       "              (shortcut): Identity()\n",
       "              (layer): Sequential(\n",
       "                (0): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): Identity()\n",
       "                )\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (1): ResNetBasicLayer(\n",
       "              (shortcut): Identity()\n",
       "              (layer): Sequential(\n",
       "                (0): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): Identity()\n",
       "                )\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ResNetStage(\n",
       "          (layers): Sequential(\n",
       "            (0): ResNetBasicLayer(\n",
       "              (shortcut): ResNetShortCut(\n",
       "                (convolution): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (layer): Sequential(\n",
       "                (0): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): Identity()\n",
       "                )\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (1): ResNetBasicLayer(\n",
       "              (shortcut): Identity()\n",
       "              (layer): Sequential(\n",
       "                (0): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): Identity()\n",
       "                )\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResNetStage(\n",
       "          (layers): Sequential(\n",
       "            (0): ResNetBasicLayer(\n",
       "              (shortcut): ResNetShortCut(\n",
       "                (convolution): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (layer): Sequential(\n",
       "                (0): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): Identity()\n",
       "                )\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (1): ResNetBasicLayer(\n",
       "              (shortcut): Identity()\n",
       "              (layer): Sequential(\n",
       "                (0): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): Identity()\n",
       "                )\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ResNetStage(\n",
       "          (layers): Sequential(\n",
       "            (0): ResNetBasicLayer(\n",
       "              (shortcut): ResNetShortCut(\n",
       "                (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (layer): Sequential(\n",
       "                (0): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): Identity()\n",
       "                )\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (1): ResNetBasicLayer(\n",
       "              (shortcut): Identity()\n",
       "              (layer): Sequential(\n",
       "                (0): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): Identity()\n",
       "                )\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "eNtkl5z3V1gq"
   },
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "filtered_dataset = ImageFolder(\"data/food-101/food-101/images\", transform=preprocess_image)\n",
    "\n",
    "chosen_indices = [*range(num_classes)] \n",
    "\n",
    "filtered_dataset.classes = [filtered_dataset.classes[i] for i in chosen_indices]\n",
    "filtered_dataset.class_to_idx = {k: i for i, k in enumerate(filtered_dataset.classes)}\n",
    "\n",
    "print(len(filtered_dataset))\n",
    "\n",
    "filtered_dataset.samples = list(filter(lambda s: s[1] in chosen_indices, filtered_dataset.samples))\n",
    "\n",
    "filtered_train_subset, filtered_test_subset = torch.utils.data.random_split(filtered_dataset, [0.8, 0.2], torch.Generator().manual_seed(42))\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(filtered_train_subset, batch_size=64, shuffle=True)\n",
    "test_dl = torch.utils.data.DataLoader(filtered_test_subset, batch_size=64, shuffle=True)\n",
    "\n",
    "print(len(filtered_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = nn.Sequential(\n",
    "                    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "                    nn.Linear(in_features=512, out_features=num_classes))\n",
    "for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "model.num_labels = num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "bnVgkUa-V1gr"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience: int, min_delta: float):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.stop = False\n",
    "        self.val_loss_min = 1e10\n",
    "        self.best_parameters = None\n",
    "\n",
    "    def __call__(self, model, val_loss):\n",
    "        if val_loss < self.val_loss_min - self.min_delta:\n",
    "            self.val_loss_min = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.stop = True\n",
    "                self.best_parameters = model.state_dict()\n",
    "\n",
    "    def get_best_model_parameters(self):\n",
    "        return self.best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "1c0-P8NDV1gs"
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "        model: torch.nn.Module,\n",
    "        epochs: int,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        early_stopping: EarlyStopping = None,\n",
    "        criterion=None\n",
    "    ):\n",
    "    criterion = criterion or torch.nn.CrossEntropyLoss()\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        train_correct = 0\n",
    "        train_outputs = 0\n",
    "\n",
    "        for i, data in enumerate(tqdm(train_dl), 0):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_correct += (torch.argmax(outputs.logits, dim=-1) == labels).sum().item()\n",
    "            train_outputs += outputs.logits.shape[0]\n",
    "\n",
    "            running_loss += loss\n",
    "\n",
    "        model.eval()\n",
    "        total_correct = 0\n",
    "        total_outputs = 0\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(tqdm(test_dl), 0):\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                val_loss += criterion(outputs.logits, labels).item()\n",
    "                correct = (torch.argmax(outputs.logits, dim=-1) == labels).sum().item()\n",
    "\n",
    "                total_correct += correct\n",
    "                total_outputs += outputs.logits.shape[0]\n",
    "\n",
    "        print(f\"[Epoch {epoch + 1}] Loss: {running_loss / i:.3f}, Train Acc: {train_correct/train_outputs:.3f},\" +\n",
    "              f\"Valid loss: {val_loss/len(test_dl):.3f} Valid Acc: {total_correct/total_outputs:.3f}\")\n",
    "\n",
    "        if early_stopping:\n",
    "            early_stopping(model, val_loss)\n",
    "            if early_stopping.stop:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "    if early_stopping:\n",
    "        model.load_state_dict(early_stopping.get_best_model_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1NmKUAtIV1gt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/125 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "early_stopping = EarlyStopping(patience=3, min_delta=0.001)\n",
    "\n",
    "train(model, num_epochs, optimizer, early_stopping=early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DEjUV_BrV1gv"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_finetuned_baseline.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BMOsjIryV1gv"
   },
   "outputs": [],
   "source": [
    "# TODO finetune the model on food101 dataset -> use TRAK -> finetune again on the base model -> look at the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "il0FxTk_YxHZ"
   },
   "outputs": [],
   "source": [
    "finetuned_path = '/content/drive/MyDrive/automating_science/model_finetuned_baseline.pth' #model_finetuned_baseline.pth\n",
    "checkpoint = torch.load(finetuned_path,  map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0x9zepxV1gx",
    "outputId": "15cffcae-4679-478d-c140-8fc85ab70597"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForImageClassification.from_pretrained(\"microsoft/resnet-18\")\n",
    "\n",
    "num_classes = 101\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "                    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "                    nn.Linear(in_features=512, out_features=num_classes))\n",
    "\n",
    "model.num_labels = num_classes\n",
    "\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jg9rdCW_dIvh"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "CA3JgPuEbNLZ"
   },
   "outputs": [],
   "source": [
    "train_dl_no_shuffle = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "test_dl_no_shuffle = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_PYwnkXehUXL"
   },
   "outputs": [],
   "source": [
    "class ResNetOutput(modelout_functions.AbstractModelOutput):\n",
    "    def get_output(\n",
    "                model: torch.nn.Module,\n",
    "                weights: Iterable[torch.Tensor],\n",
    "                buffers: Iterable[torch.Tensor],\n",
    "                image: torch.Tensor,\n",
    "                label: torch.Tensor\n",
    "      ):\n",
    "      for key, value in weights.items():\n",
    "        weights[key] = weights[key].to(device)\n",
    "      output = torch.func.functional_call(model, (weights, buffers), image.unsqueeze(0))\n",
    "      logits = output.logits #our change\n",
    "      bindex = torch.arange(logits.shape[0]).to(logits.device, non_blocking=False)\n",
    "      logits_correct = logits[bindex, label.unsqueeze(0)]\n",
    "\n",
    "      cloned_logits = logits.clone()\n",
    "\n",
    "      cloned_logits[bindex, label.unsqueeze(0)] = torch.tensor(-torch.inf, device=logits.device, dtype=logits.dtype)\n",
    "\n",
    "      margins = logits_correct - cloned_logits.logsumexp(dim=-1)\n",
    "      return margins.sum()\n",
    "    def get_out_to_loss_grad(self, model, weights, buffers, batch):\n",
    "      for key, value in weights.items():\n",
    "        weights[key] = weights[key].to(device)\n",
    "      images, labels = batch\n",
    "      output = torch.func.functional_call(model, (weights, buffers), images)\n",
    "      logits = output.logits #our change\n",
    "\n",
    "      ps = self.softmax(logits / self.loss_temperature)[torch.arange(logits.size(0)), labels]\n",
    "      return (1 - ps).clone().detach().unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6XN4FUNGV1gx",
    "outputId": "5efe328f-6aea-48ae-86a9-36d1a797d924"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:TRAK:Could not use CudaProjector.\n",
      "Reason: No module named 'fast_jl'\n",
      "ERROR:TRAK:Defaulting to BasicProjector.\n",
      "INFO:STORE:Existing model IDs in /content/trak_results: [0]\n",
      "INFO:STORE:No model IDs in /content/trak_results have been finalized.\n",
      "INFO:STORE:No existing TRAK scores in /content/trak_results.\n"
     ]
    }
   ],
   "source": [
    "traker = TRAKer(model=model,\n",
    "                task=ResNetOutput(),\n",
    "                train_set_size=len(train_dl_no_shuffle.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "35EBBpCib2UY"
   },
   "outputs": [],
   "source": [
    "model_id = 0\n",
    "traker.load_checkpoint(torch.load(finetuned_path,  map_location=device), model_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "id": "lGhzNkJvV1gy",
    "outputId": "33963680-a114-46ca-d1d2-e1091bf0793c"
   },
   "outputs": [],
   "source": [
    "for data in train_dl_no_shuffle:\n",
    "    data = [xy.cuda() for xy in data]\n",
    "\n",
    "    traker.featurize(batch=data, num_samples=data[0].shape[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
