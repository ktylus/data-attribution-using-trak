{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xXkrH43GV-sW",
    "outputId": "37a9f19a-251d-40f5-dc9b-54779caf48e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EEAzrolWXQNc",
    "outputId": "fe1ef283-9b5b-404d-a777-0dbe6eb634f9"
   },
   "outputs": [],
   "source": [
    "!pip install traker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ONmWcrKn6A0y",
    "outputId": "e2c49982-d960-40e8-ab4a-f21eacc9b4c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "from torchvision.datasets import Food101, ImageFolder\n",
    "from trak import TRAKer\n",
    "from trak import modelout_functions\n",
    "from collections.abc import Iterable\n",
    "\n",
    "from src.train import train_model\n",
    "from src.early_stopping import EarlyStopping\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ue3_pIWcV1gm",
    "outputId": "33407e57-d744-4b67-dc3a-5320f920ca6d"
   },
   "outputs": [],
   "source": [
    "processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-18\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"microsoft/resnet-18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vYAkNawuV1gn"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = transforms.functional.pil_to_tensor(image)\n",
    "    processed_image = processor.preprocess(image)[\"pixel_values\"][0]\n",
    "    return torch.from_numpy(processed_image)\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "train_dataset = Food101(\"data/food-101\", split=\"train\", transform=preprocess_image, download=False)\n",
    "test_dataset = Food101(\"data/food-101\", split=\"test\", transform=preprocess_image, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "filtered_dataset = ImageFolder(\"data/food-101/food-101/images\", transform=preprocess_image)\n",
    "\n",
    "chosen_indices = [*range(num_classes)] \n",
    "\n",
    "filtered_dataset.classes = [filtered_dataset.classes[i] for i in chosen_indices]\n",
    "filtered_dataset.class_to_idx = {k: i for i, k in enumerate(filtered_dataset.classes)}\n",
    "\n",
    "print(len(filtered_dataset))\n",
    "\n",
    "filtered_dataset.samples = list(filter(lambda s: s[1] in chosen_indices, filtered_dataset.samples))\n",
    "\n",
    "filtered_train_subset, filtered_test_subset = torch.utils.data.random_split(filtered_dataset, [0.8, 0.2], torch.Generator().manual_seed(42))\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(filtered_train_subset, batch_size=64, shuffle=True)\n",
    "test_dl = torch.utils.data.DataLoader(filtered_test_subset, batch_size=64, shuffle=True)\n",
    "\n",
    "print(len(filtered_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = nn.Sequential(\n",
    "                    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "                    nn.Linear(in_features=512, out_features=num_classes))\n",
    "for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "model.num_labels = num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1NmKUAtIV1gt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [02:28<00:00,  1.19s/it]\n",
      "100%|██████████| 32/32 [00:23<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Loss: 3.937, Train Acc: 0.675,Valid loss: 1.105 Valid Acc: 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [01:45<00:00,  1.19it/s]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Loss: 2.393, Train Acc: 0.801,Valid loss: 1.425 Valid Acc: 0.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [01:45<00:00,  1.19it/s]\n",
      "100%|██████████| 32/32 [00:23<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Loss: 1.711, Train Acc: 0.861,Valid loss: 0.869 Valid Acc: 0.714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [01:45<00:00,  1.18it/s]\n",
      "100%|██████████| 32/32 [00:23<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Loss: 1.267, Train Acc: 0.891,Valid loss: 1.309 Valid Acc: 0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [03:26<00:00,  1.65s/it]\n",
      "100%|██████████| 32/32 [00:49<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Loss: 0.925, Train Acc: 0.921,Valid loss: 1.143 Valid Acc: 0.684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [03:06<00:00,  1.49s/it]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Loss: 0.705, Train Acc: 0.939,Valid loss: 1.132 Valid Acc: 0.714\n",
      "Early stopping at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "early_stopping = EarlyStopping(patience=3, min_delta=0.001)\n",
    "\n",
    "train_model(model, train_dl, test_dl, num_epochs, optimizer, early_stopping=early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DEjUV_BrV1gv"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_finetuned_baseline.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "il0FxTk_YxHZ"
   },
   "outputs": [],
   "source": [
    "#finetuned_path = '/content/drive/MyDrive/automating_science/model_finetuned_baseline.pth' #model_finetuned_baseline.pth\n",
    "finetuned_path = \"model_finetuned_baseline.pth\"\n",
    "checkpoint = torch.load(finetuned_path,  map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0x9zepxV1gx",
    "outputId": "15cffcae-4679-478d-c140-8fc85ab70597"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = AutoModelForImageClassification.from_pretrained(\"microsoft/resnet-18\")\n",
    "\n",
    "#model.classifier = nn.Sequential(\n",
    "#                    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "#                   nn.Linear(in_features=512, out_features=num_classes))\n",
    "\n",
    "#model.num_labels = num_classes\n",
    "\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jg9rdCW_dIvh"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CA3JgPuEbNLZ"
   },
   "outputs": [],
   "source": [
    "train_dl_no_shuffle = torch.utils.data.DataLoader(filtered_train_subset, batch_size=32, shuffle=False)\n",
    "test_dl_no_shuffle = torch.utils.data.DataLoader(filtered_test_subset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_PYwnkXehUXL"
   },
   "outputs": [],
   "source": [
    "class ResNetOutput(modelout_functions.AbstractModelOutput):\n",
    "    def __init__(self, loss_temperature: float = 1.0):\n",
    "       super().__init__()\n",
    "       self.softmax = nn.Softmax(dim=-1)\n",
    "       self.loss_temperature = loss_temperature\n",
    "\n",
    "    @staticmethod\n",
    "    def get_output(\n",
    "                model: torch.nn.Module,\n",
    "                weights: Iterable[torch.Tensor],\n",
    "                buffers: Iterable[torch.Tensor],\n",
    "                image: torch.Tensor,\n",
    "                label: torch.Tensor\n",
    "      ):\n",
    "      for key, value in weights.items():\n",
    "        weights[key] = weights[key].to(device)\n",
    "      output = torch.func.functional_call(model, (weights, buffers), image.unsqueeze(0))\n",
    "      logits = output.logits #our change\n",
    "      bindex = torch.arange(logits.shape[0]).to(logits.device, non_blocking=False)\n",
    "      logits_correct = logits[bindex, label.unsqueeze(0)]\n",
    "\n",
    "      cloned_logits = logits.clone()\n",
    "\n",
    "      cloned_logits[bindex, label.unsqueeze(0)] = torch.tensor(-torch.inf, device=logits.device, dtype=logits.dtype)\n",
    "\n",
    "      margins = logits_correct - cloned_logits.logsumexp(dim=-1)\n",
    "      return margins.sum()\n",
    "    \n",
    "    def get_out_to_loss_grad(self, model, weights, buffers, batch):\n",
    "      for key, value in weights.items():\n",
    "        weights[key] = weights[key].to(device)\n",
    "      images, labels = batch\n",
    "      output = torch.func.functional_call(model, (weights, buffers), images)\n",
    "      logits = output.logits #our change\n",
    "\n",
    "      ps = self.softmax(logits / self.loss_temperature)[torch.arange(logits.size(0)), labels]\n",
    "      return (1 - ps).clone().detach().unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6XN4FUNGV1gx",
    "outputId": "5efe328f-6aea-48ae-86a9-36d1a797d924"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:TRAK:Could not use CudaProjector.\n",
      "Reason: No module named 'fast_jl'\n",
      "ERROR:TRAK:Defaulting to BasicProjector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:STORE:No existing model IDs in C:\\Users\\kamil\\OneDrive\\Pulpit\\przedmioty\\semestr 8\\automating science\\trak-for-automating-science\\trak_results.\n",
      "INFO:STORE:No existing TRAK scores in C:\\Users\\kamil\\OneDrive\\Pulpit\\przedmioty\\semestr 8\\automating science\\trak-for-automating-science\\trak_results.\n"
     ]
    }
   ],
   "source": [
    "traker = TRAKer(model=model,\n",
    "                task=ResNetOutput(),\n",
    "                train_set_size=len(train_dl_no_shuffle.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "35EBBpCib2UY"
   },
   "outputs": [],
   "source": [
    "model_id = 0\n",
    "traker.load_checkpoint(checkpoint, model_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "id": "lGhzNkJvV1gy",
    "outputId": "33963680-a114-46ca-d1d2-e1091bf0793c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]c:\\Users\\kamil\\anaconda3\\envs\\ml_gnn\\lib\\site-packages\\torch\\autograd\\graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "100%|██████████| 250/250 [21:34<00:00,  5.18s/it]\n"
     ]
    }
   ],
   "source": [
    "for data in tqdm(train_dl_no_shuffle):\n",
    "    data = [xy.cuda() for xy in data]\n",
    "\n",
    "    traker.featurize(batch=data, num_samples=data[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finalizing features for all model IDs..: 100%|██████████| 1/1 [00:00<00:00,  2.64it/s]\n"
     ]
    }
   ],
   "source": [
    "traker.finalize_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [2:33:00<00:00, 36.72s/it]  \n",
      "Finalizing scores for all model IDs..: 100%|██████████| 1/1 [00:00<00:00,  1.93it/s]\n",
      "INFO:STORE:Saving scores in C:\\Users\\kamil\\OneDrive\\Pulpit\\przedmioty\\semestr 8\\automating science\\trak-for-automating-science\\trak_results\\scores/test.mmap\n"
     ]
    }
   ],
   "source": [
    "traker.start_scoring_checkpoint(exp_name=\"test\", checkpoint=checkpoint, model_id=model_id, num_targets=len(train_dl_no_shuffle.dataset))\n",
    "for batch in tqdm(train_dl_no_shuffle):\n",
    "    batch = [xy.cuda() for xy in batch]\n",
    "    traker.score(batch=batch, num_samples=batch[0].shape[0])\n",
    "\n",
    "scores = traker.finalize_scores(exp_name=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 8000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 62/63 [39:03<00:35, 35.80s/it]c:\\Users\\kamil\\anaconda3\\envs\\ml_gnn\\lib\\site-packages\\torch\\autograd\\graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "100%|██████████| 63/63 [39:41<00:00, 37.80s/it]\n",
      "Finalizing scores for all model IDs..: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s]\n",
      "INFO:STORE:Saving scores in C:\\Users\\kamil\\OneDrive\\Pulpit\\przedmioty\\semestr 8\\automating science\\trak-for-automating-science\\trak_results\\scores/test_val.mmap\n"
     ]
    }
   ],
   "source": [
    "traker.start_scoring_checkpoint(exp_name=\"test_val\", checkpoint=checkpoint, model_id=model_id, num_targets=len(test_dl_no_shuffle.dataset))\n",
    "for batch in tqdm(test_dl_no_shuffle):\n",
    "    batch = [xy.cuda() for xy in batch]\n",
    "    traker.score(batch=batch, num_samples=batch[0].shape[0])\n",
    "\n",
    "test_scores = traker.finalize_scores(exp_name=\"test_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 2000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.save(\"train_scores.npy\", scores)\n",
    "np.save(\"test_scores.npy\", test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
